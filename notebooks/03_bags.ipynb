{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import defaultdict\n",
    "from spellchecker import SpellChecker\n",
    "from kedro.pipeline.decorators import log_time\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-18 09:45:45,829 - kedro.io.data_catalog - INFO - Loading data from `reviews_master` (PickleLocalDataSet)...\n"
     ]
    }
   ],
   "source": [
    "reviews = io.load('reviews_master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip punctuation\n",
    "\n",
    "def _remove_punc(text):\n",
    "    return re.sub(r'[^\\w\\s]','', text)\n",
    "\n",
    "# Remove repeated letters \n",
    "\n",
    "def _remove_repeats(lst):\n",
    "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
    "    return [pattern.sub(r\"\\1\", w) for w in lst]\n",
    "\n",
    "# Fix spelling\n",
    "\n",
    "spell = SpellChecker()\n",
    "\n",
    "def  _fix_spelling(lst):\n",
    "    return [spell.correction(x) for x in lst]\n",
    "\n",
    "# Stem words\n",
    "\n",
    "porter = nltk.PorterStemmer() \n",
    "\n",
    "def _stem(lst):\n",
    "    return [porter.stem(x) for x in lst]\n",
    "\n",
    "# Lemmaatisation\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts.\n",
    "    Source: https://www.machinelearningplus.com/nlp/lemmatization-examples-python/\n",
    "    \"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def _lemmatize(lst):\n",
    "    return [wnl.lemmatize(w, get_wordnet_pos(w)) for w in lst]\n",
    "\n",
    "# Remove stop words\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words = [_remove_punc(x) for x in stop_words]\n",
    "\n",
    "def _remove_stops(lst):\n",
    "    return [x for x in lst if x not in stop_words]\n",
    "\n",
    "# Count words \n",
    "\n",
    "def _count_words(lst):\n",
    "    word_freq = defaultdict(int)\n",
    "    for w in lst:\n",
    "        word_freq[w] += 1\n",
    "    return dict(word_freq)\n",
    "\n",
    "def create_bag(text):\n",
    "    # extract emoticons\n",
    "    text = _remove_punc(text)\n",
    "    text = text.lower()\n",
    "    words = nltk.word_tokenize(text)\n",
    "#     words = _remove_extensions(words)\n",
    "#     words = _fix_spelling(words)\n",
    "#     words = _remove_stops(words)\n",
    "#     words = _lemmatize(words)\n",
    "    words = _stem(words)\n",
    "    freq = _count_words(words)\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bag(text):\n",
    "    text = _remove_punc(text)\n",
    "    text = text.lower()\n",
    "    words = nltk.word_tokenize(text)\n",
    "#     words = _remove_extensions(words)\n",
    "#     words = _fix_spelling(words)\n",
    "    words = _remove_stops(words)\n",
    "#     words = _lemmatize(words)\n",
    "    freq = _count_words(words)\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "0        {'absolutely': 1, 'wonderful': 1, 'silky': 1, ...\n",
       "1        {'love': 2, 'dress': 1, 'sooo': 1, 'pretty': 1...\n",
       "2        {'high': 1, 'hopes': 1, 'dress': 1, 'really': ...\n",
       "3        {'love': 3, 'jumpsuit': 1, 'fun': 1, 'flirty':...\n",
       "4        {'shirt': 2, 'flattering': 1, 'due': 1, 'adjus...\n",
       "5        {'love': 2, 'tracy': 1, 'reese': 1, 'dresses':...\n",
       "6        {'aded': 1, 'basket': 1, 'hte': 4, 'last': 1, ...\n",
       "7        {'ordered': 1, 'carbon': 1, 'store': 1, 'pick'...\n",
       "8        {'love': 1, 'dress': 1, 'usually': 1, 'get': 1...\n",
       "9        {'im': 1, '55': 1, '125': 1, 'lbs': 1, 'ordere...\n",
       "10       {'dress': 2, 'runs': 2, 'small': 1, 'esp': 1, ...\n",
       "11       {'dress': 1, 'perfection': 1, 'pretty': 1, 'fl...\n",
       "12       {'find': 1, 'reliant': 1, 'reviews': 1, 'writt...\n",
       "13       {'bought': 1, 'black': 1, 'xs': 2, 'go': 1, 'l...\n",
       "14       {'nice': 1, 'choice': 1, 'holiday': 1, 'gather...\n",
       "15       {'took': 1, 'package': 1, 'wanted': 1, 'fit': ...\n",
       "16       {'material': 1, 'color': 1, 'nice': 1, 'leg': ...\n",
       "17       {'took': 1, 'chance': 1, 'blouse': 2, 'glad': ...\n",
       "18       {'flattering': 1, 'super': 1, 'cozy': 1, 'coat...\n",
       "19       {'love': 1, 'look': 2, 'feel': 1, 'tulle': 2, ...\n",
       "20       {'product': 1, 'petite': 2, 'would': 1, 'get':...\n",
       "21       {'im': 1, 'upset': 1, 'price': 2, 'dress': 1, ...\n",
       "22       {'first': 1, 'pullover': 1, 'styling': 1, 'sid...\n",
       "23       {'cute': 1, 'little': 2, 'dress': 2, 'fits': 1...\n",
       "24       {'love': 1, 'shirt': 2, 'first': 1, 'saw': 1, ...\n",
       "25       {'loved': 1, 'material': 2, 'really': 1, 'look...\n",
       "26       {'waiting': 1, 'sweater': 1, 'coat': 3, 'ship'...\n",
       "27       {'colors': 1, 'expected': 1, 'either': 1, 'dar...\n",
       "28       {'several': 1, 'goodhyouman': 1, 'shirts': 1, ...\n",
       "29       {'sweater': 1, 'comfy': 1, 'classic': 1, 'bala...\n",
       "                               ...                        \n",
       "23454    {'fabric': 3, 'thick': 1, 'textured': 1, 'almo...\n",
       "23455    {'cute': 1, 'dress': 2, 'keep': 1, 'mainly': 1...\n",
       "23456    {'search': 1, 'dress': 2, 'sleeves': 1, 'cute'...\n",
       "23457    {'pants': 1, 'soft': 1, 'fun': 1, 'print': 1, ...\n",
       "23458    {'new': 1, 'favorite': 1, 'sweater': 1, 'light...\n",
       "23459    {'new': 1, 'favorite': 1, 'dress': 4, 'complai...\n",
       "23460    {'purchased': 1, 'good': 1, 'price': 1, 'typic...\n",
       "23461    {'tried': 1, 'store': 1, 'fit': 1, 'good': 1, ...\n",
       "23462    {'pattern': 1, 'skirt': 1, 'adorable': 1, 'loo...\n",
       "23463    {'pants': 2, 'overall': 1, 'comfortable': 1, '...\n",
       "23464    {'wore': 1, 'dress': 2, 'work': 1, 'day': 1, '...\n",
       "23465    {'bought': 1, 'dress': 1, 'work': 3, 'post': 1...\n",
       "23466    {'dress': 1, 'great': 2, 'design': 1, 'fits': ...\n",
       "23467    {'worry': 1, 'elastic': 1, 'waist': 1, 'someth...\n",
       "23468    {'love': 1, 'little': 1, 'chemise': 1, 'adjust...\n",
       "23469    {'size': 3, 'available': 1, 'based': 1, 'revie...\n",
       "23471    {'love': 1, 'way': 1, 'pants': 1, 'look': 1, '...\n",
       "23472    {'saw': 1, 'shirt': 1, 'retailer': 1, 'website...\n",
       "23473    {'great': 1, 'quality': 1, 'extremely': 1, 'fl...\n",
       "23474    {'yes': 1, 'great': 3, 'dress': 2, 'sure': 1, ...\n",
       "23475    {'cute': 1, 'dress': 2, 'waist': 1, 'high': 1,...\n",
       "23476    {'bottoms': 1, 'cute': 1, 'defiantly': 1, 'che...\n",
       "23477    {'im': 1, 'impressed': 1, 'beautiful': 1, 'col...\n",
       "23478    {'surprised': 1, 'positive': 1, 'reviews': 1, ...\n",
       "23479    {'sure': 1, 'ordering': 1, 'skirt': 3, 'see': ...\n",
       "23481    {'happy': 1, 'snag': 1, 'dress': 1, 'great': 1...\n",
       "23482    {'reminds': 1, 'maternity': 1, 'clothes': 1, '...\n",
       "23483    {'fit': 1, 'well': 1, 'top': 1, 'see': 1, 'nev...\n",
       "23484    {'bought': 1, 'dress': 2, 'wedding': 1, 'summe...\n",
       "23485    {'dress': 1, 'lovely': 1, 'platinum': 1, 'femi...\n",
       "Name: review_text, Length: 22641, dtype: object"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = reviews['review_text']\n",
    "bags = corpus.apply(create_bag)\n",
    "bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def _intersect_terms(doc1, doc2):\n",
    "    return  list(set(list(doc1.keys()) + list(doc2.keys())))\n",
    "\n",
    "def term_vector(doc, terms = []):\n",
    "    local_terms = list(doc.keys())\n",
    "    global_terms = list(set(local_terms + terms))\n",
    "    return [doc[term] if term in local_terms else 0 for term in global_terms]\n",
    "   \n",
    "def cosine_sim(doc1, doc2):\n",
    "    terms = _intersect_terms(doc1, doc2)\n",
    "    X = [term_vector(doc1, terms), term_vector(doc2, terms)]\n",
    "    X = sklearn.preprocessing.normalize(X) # normalize the rows of X\n",
    "    return np.dot(X[0], X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34099716973523675"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1 = bags.loc[0]\n",
    "doc2 = bags.loc[1]\n",
    "cosine_sim(doc1, doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_frequency(docs, cutoff = 0):\n",
    "    \"\"\"Given a list of {token: freq} dicts (ie as returned by get_document_terms),\n",
    "    returns a {token:freq} dict. The frequencies of this return dictionary\n",
    "    represent the number of documents each term appears in.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    freqs = defaultdict(int)\n",
    "\n",
    "    for doc in docs:\n",
    "        for term in doc.keys():\n",
    "            freqs[term] += 1\n",
    "            \n",
    "    freqs = {term: freq for term, freq in freqs.items() if freq > cutoff}\n",
    "\n",
    "    return pd.Series(freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "love              7402\n",
       "size              6539\n",
       "fit               6139\n",
       "dress             6039\n",
       "like              5725\n",
       "wear              5520\n",
       "top               5264\n",
       "great             5175\n",
       "im                4897\n",
       "would             4290\n",
       "fabric            4119\n",
       "color             4018\n",
       "small             3648\n",
       "look              3502\n",
       "ordered           3455\n",
       "really            3380\n",
       "perfect           3347\n",
       "flattering        3312\n",
       "little            3283\n",
       "soft              3151\n",
       "one               3071\n",
       "comfortable       2926\n",
       "well              2926\n",
       "back              2811\n",
       "cute              2784\n",
       "beautiful         2750\n",
       "fits              2690\n",
       "nice              2676\n",
       "bought            2669\n",
       "looks             2588\n",
       "                  ... \n",
       "bummers              1\n",
       "verticallyand        1\n",
       "resent               1\n",
       "growths              1\n",
       "jodphurs             1\n",
       "rackerback           1\n",
       "382738               1\n",
       "5ft8inches           1\n",
       "softi                1\n",
       "sunning              1\n",
       "2100                 1\n",
       "2999                 1\n",
       "incidents            1\n",
       "ash                  1\n",
       "pantlegging          1\n",
       "jacketsmy            1\n",
       "fittinghits          1\n",
       "delicatecasual       1\n",
       "retailerthe          1\n",
       "embraces             1\n",
       "obscures             1\n",
       "dizzying             1\n",
       "shortcake            1\n",
       "excell               1\n",
       "peachypink           1\n",
       "30s40s               1\n",
       "outweighed           1\n",
       "anniversaryi         1\n",
       "petiteregular        1\n",
       "floofs               1\n",
       "Length: 19219, dtype: int64"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_freqs = get_document_frequency(bags)\n",
    "doc_freqs.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _idf(term):\n",
    "    return math.log2(N_docs / doc_freqs[term])\n",
    "\n",
    "def tfidf(dct):\n",
    "    return {term: math.log2(1 + freq) * _idf(term) for term, freq in dct.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "0        {'absolutely': 4.831839009419443, 'wonderful':...\n",
       "1        {'love': 2.556466278790357, 'dress': 1.9065561...\n",
       "2        {'high': 4.544809122516671, 'hopes': 7.9120612...\n",
       "3        {'love': 3.2259012785818815, 'jumpsuit': 7.040...\n",
       "4        {'shirt': 5.720837490467469, 'flattering': 2.7...\n",
       "5        {'love': 2.556466278790357, 'tracy': 9.5597594...\n",
       "6        {'aded': 14.466650059591162, 'basket': 10.7662...\n",
       "7        {'ordered': 2.7121800643155405, 'carbon': 10.7...\n",
       "8        {'love': 1.6129506392909407, 'dress': 1.906556...\n",
       "9        {'im': 2.2089675788823953, '55': 5.55975946398...\n",
       "10       {'dress': 3.021819927109736, 'runs': 6.0165078...\n",
       "11       {'dress': 1.9065561019486652, 'perfection': 8....\n",
       "12       {'find': 4.664133694469938, 'reliant': 14.4666...\n",
       "13       {'bought': 3.0845664694491948, 'black': 3.9618...\n",
       "14       {'nice': 3.0807876589497, 'choice': 8.00721844...\n",
       "15       {'took': 5.665750159670856, 'package': 7.79422...\n",
       "16       {'material': 3.1628693114140582, 'color': 2.49...\n",
       "17       {'took': 5.665750159670856, 'chance': 7.389834...\n",
       "18       {'flattering': 2.773163102091836, 'super': 3.8...\n",
       "19       {'love': 1.6129506392909407, 'look': 4.2678074...\n",
       "20       {'product': 7.091610628244236, 'petite': 5.718...\n",
       "21       {'im': 2.2089675788823953, 'upset': 10.6592951...\n",
       "22       {'first': 4.311831950539057, 'pullover': 8.535...\n",
       "23       {'cute': 3.023706563742433, 'little': 4.415469...\n",
       "24       {'love': 1.6129506392909407, 'shirt': 5.720837...\n",
       "25       {'loved': 4.224666909896833, 'material': 5.013...\n",
       "26       {'waiting': 8.23783136909528, 'sweater': 3.632...\n",
       "27       {'colors': 3.371912554543068, 'expected': 5.72...\n",
       "28       {'several': 6.2378313690952805, 'goodhyouman':...\n",
       "29       {'sweater': 3.6329693109364194, 'comfy': 4.771...\n",
       "                               ...                        \n",
       "23454    {'fabric': 4.917143297445809, 'thick': 5.48937...\n",
       "23455    {'cute': 3.023706563742433, 'dress': 3.0218199...\n",
       "23456    {'search': 9.76621034145007, 'dress': 3.021819...\n",
       "23457    {'pants': 3.997008242351645, 'soft': 2.8450560...\n",
       "23458    {'new': 5.912061207913524, 'favorite': 5.42499...\n",
       "23459    {'new': 5.912061207913524, 'favorite': 5.42499...\n",
       "23460    {'purchased': 4.009269180518626, 'good': 3.654...\n",
       "23461    {'tried': 3.5863012514351347, 'store': 3.65367...\n",
       "23462    {'pattern': 4.660906187439542, 'skirt': 4.0268...\n",
       "23463    {'pants': 6.335108179200736, 'overall': 4.8427...\n",
       "23464    {'wore': 4.688572930055803, 'dress': 3.0218199...\n",
       "23465    {'bought': 3.0845664694491948, 'dress': 1.9065...\n",
       "23466    {'dress': 1.9065561019486652, 'great': 3.37487...\n",
       "23467    {'worry': 8.109098054973078, 'elastic': 6.6592...\n",
       "23468    {'love': 1.6129506392909407, 'little': 2.78585...\n",
       "23469    {'size': 3.583591503289084, 'available': 6.422...\n",
       "23471    {'love': 1.6129506392909407, 'way': 3.72940271...\n",
       "23472    {'saw': 4.50809734416015, 'shirt': 3.609446588...\n",
       "23473    {'great': 2.129306912317111, 'quality': 3.3965...\n",
       "23474    {'yes': 7.007218440953864, 'great': 4.25861382...\n",
       "23475    {'cute': 3.023706563742433, 'dress': 3.0218199...\n",
       "23476    {'bottoms': 7.209262216898509, 'cute': 3.02370...\n",
       "23477    {'im': 2.2089675788823953, 'impressed': 8.5840...\n",
       "23478    {'surprised': 6.242648385393056, 'positive': 8...\n",
       "23479    {'sure': 4.643282819544926, 'ordering': 6.3322...\n",
       "23481    {'happy': 5.040385304889063, 'snag': 7.7942247...\n",
       "23482    {'reminds': 8.685290346066502, 'maternity': 6....\n",
       "23483    {'fit': 1.882862105088824, 'well': 2.951936005...\n",
       "23484    {'bought': 3.0845664694491948, 'dress': 3.0218...\n",
       "23485    {'dress': 1.9065561019486652, 'lovely': 4.4808...\n",
       "Name: review_text, Length: 22641, dtype: object"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bags.apply(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_tfidf(bags):\n",
    "    bags = bags.apply(tfidf)\n",
    "    means = defaultdict(int)\n",
    "\n",
    "    for bag in bags:\n",
    "        for term in bag.keys():\n",
    "            means[term] += bag[term]\n",
    "    \n",
    "    for term in means.keys():\n",
    "        means[term] /= doc_freqs[term]\n",
    "\n",
    "    return pd.Series(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tule                28.933300\n",
       "â                   28.933300\n",
       "evanthe             28.933300\n",
       "reflected           22.929098\n",
       "roaming             22.929098\n",
       "27r                 22.929098\n",
       "champion            22.929098\n",
       "wobbly              22.929098\n",
       "eu                  22.929098\n",
       "boxing              22.929098\n",
       "cohs                22.929098\n",
       "moors               22.929098\n",
       "orangeblue          22.929098\n",
       "librarian           22.929098\n",
       "corodorys           22.929098\n",
       "llama               22.929098\n",
       "seea                22.929098\n",
       "bluepurplesilver    22.929098\n",
       "gripper             22.929098\n",
       "riverdeck           22.929098\n",
       "p2                  22.929098\n",
       "haute               22.929098\n",
       "stetson             22.929098\n",
       "rona                22.929098\n",
       "allison             22.929098\n",
       "mui                 22.929098\n",
       "whoop               22.929098\n",
       "spokane             22.929098\n",
       "coveralls           22.929098\n",
       "marroon             22.929098\n",
       "                      ...    \n",
       "looks                3.316904\n",
       "nice                 3.299070\n",
       "bought               3.292045\n",
       "back                 3.228856\n",
       "fits                 3.180446\n",
       "cute                 3.169302\n",
       "beautiful            3.158096\n",
       "one                  3.146280\n",
       "well                 3.131625\n",
       "little               3.020624\n",
       "comfortable          3.013216\n",
       "really               2.991387\n",
       "small                2.986693\n",
       "perfect              2.937607\n",
       "soft                 2.926972\n",
       "look                 2.915561\n",
       "ordered              2.882764\n",
       "flattering           2.855210\n",
       "color                2.683425\n",
       "fabric               2.673470\n",
       "would                2.626589\n",
       "dress                2.625198\n",
       "top                  2.545634\n",
       "im                   2.480689\n",
       "great                2.338055\n",
       "like                 2.226117\n",
       "wear                 2.222277\n",
       "size                 2.108412\n",
       "fit                  2.072737\n",
       "love                 1.793287\n",
       "Length: 19219, dtype: float64"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_tfidf = get_avg_tfidf(bags)\n",
    "avg_tfidf.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_search(term):\n",
    "    \"\"\"Search the documents\n",
    "    \"\"\"\n",
    "    matches = [(i, bags.iloc[i]) for i in range(len(bags)) if term in bags.iloc[i].keys()]\n",
    "    counts = sorted([(bag[term], i) for i, bag in matches], reverse = True)\n",
    "    return counts[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id                                                                  1056\n",
       "author_age                                                                    54\n",
       "review_title                                          Most stylish chinos around\n",
       "review_text                    I bought these in pink and added taupe to my w...\n",
       "star_rating                                                                    5\n",
       "recommend_flag                                                                 1\n",
       "upvotes                                                                        1\n",
       "product_category_division                                                general\n",
       "product_category_department                                              bottoms\n",
       "product_category_class                                                     pants\n",
       "Name: 9734, dtype: object"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_search(\"tule\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
