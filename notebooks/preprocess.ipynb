{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'emoji'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c9ef77d3234d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspellchecker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpellChecker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkedro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlog_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0memoji\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtextacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'emoji'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "from spellchecker import SpellChecker\n",
    "from kedro.pipeline.decorators import log_time\n",
    "import emoji\n",
    "import spacy\n",
    "import textacy\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "ename": "DataSetNotFoundError",
     "evalue": "DataSet 'reviews_master' not found in the catalog",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataSetNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-38f1a29a57ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'reviews_master'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/kedro/io/data_catalog.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mDataSetNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DataSet '{}' not found in the catalog\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDataSetNotFoundError\u001b[0m: DataSet 'reviews_master' not found in the catalog"
     ]
    }
   ],
   "source": [
    "reviews = io.load('reviews_master')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rules for Text Cleaning:\n",
    "- Short hand abbrev:\n",
    "    + bc -> because\n",
    "- Repeating words (sooo):\n",
    "    + regex??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add special case rule\n",
    "from spacy.attrs import ORTH, LEMMA, POS\n",
    "\n",
    "special_case = [{ORTH: u\"bc\", LEMMA: u\"because\", POS: u\"CONJ\"}]\n",
    "nlp.tokenizer.add_special_case(u\"bc\", special_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = emoji.demojize(text)\n",
    "    return textacy.preprocess.preprocess_text(text, False, \n",
    "                                              lowercase=True, no_urls=True, \n",
    "                                              no_emails=True, no_phone_numbers=True, \n",
    "                                              no_numbers=True, no_currency_symbols=False, \n",
    "                                              no_punct=True, no_contractions=False, \n",
    "                                              no_accents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e068c0d976254f3eab1f0c752e48a62d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=22641), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reviews['clean_text'] = reviews['review_text'].progress_apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>author_age</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>recommend_flag</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>product_category_division</th>\n",
       "      <th>product_category_department</th>\n",
       "      <th>product_category_class</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>intimates</td>\n",
       "      <td>intimate</td>\n",
       "      <td>intimates</td>\n",
       "      <td>absolutely wonderful silky and sexy and comfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>general</td>\n",
       "      <td>dresses</td>\n",
       "      <td>dresses</td>\n",
       "      <td>love this dress it s sooo pretty i happened to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>dresses</td>\n",
       "      <td>dresses</td>\n",
       "      <td>i had such high hopes for this dress and reall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>general petite</td>\n",
       "      <td>bottoms</td>\n",
       "      <td>pants</td>\n",
       "      <td>i love love love this jumpsuit it s fun flirty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>general</td>\n",
       "      <td>tops</td>\n",
       "      <td>blouses</td>\n",
       "      <td>this shirt is very flattering to all due to th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id  author_age             review_title  \\\n",
       "id                                                    \n",
       "0          767          33                      NaN   \n",
       "1         1080          34                      NaN   \n",
       "2         1077          60  Some major design flaws   \n",
       "3         1049          50         My favorite buy!   \n",
       "4          847          47         Flattering shirt   \n",
       "\n",
       "                                          review_text  star_rating  \\\n",
       "id                                                                   \n",
       "0   Absolutely wonderful - silky and sexy and comf...            4   \n",
       "1   Love this dress!  it's sooo pretty.  i happene...            5   \n",
       "2   I had such high hopes for this dress and reall...            3   \n",
       "3   I love, love, love this jumpsuit. it's fun, fl...            5   \n",
       "4   This shirt is very flattering to all due to th...            5   \n",
       "\n",
       "    recommend_flag  upvotes product_category_division  \\\n",
       "id                                                      \n",
       "0                1        0                 intimates   \n",
       "1                1        4                   general   \n",
       "2                0        0                   general   \n",
       "3                1        0            general petite   \n",
       "4                1        6                   general   \n",
       "\n",
       "   product_category_department product_category_class  \\\n",
       "id                                                      \n",
       "0                     intimate              intimates   \n",
       "1                      dresses                dresses   \n",
       "2                      dresses                dresses   \n",
       "3                      bottoms                  pants   \n",
       "4                         tops                blouses   \n",
       "\n",
       "                                           clean_text  \n",
       "id                                                     \n",
       "0   absolutely wonderful silky and sexy and comfor...  \n",
       "1   love this dress it s sooo pretty i happened to...  \n",
       "2   i had such high hopes for this dress and reall...  \n",
       "3   i love love love this jumpsuit it s fun flirty...  \n",
       "4   this shirt is very flattering to all due to th...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452da0c6854f446798109f40e298b7b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Calculating TF-iDF', max=22641, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "analyzer = TfidfVectorizer().build_analyzer()\n",
    "stemmer = nltk.PorterStemmer()\n",
    "def stemmed_words(doc):\n",
    "    return list(map(stemmer.stem, analyzer(doc)) )\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), \n",
    "                             stop_words='english',\n",
    "                             analyzer=stemmed_words,\n",
    "                             norm='l1')\n",
    "corpus = list(reviews['clean_text'])\n",
    "\n",
    "X = vectorizer.fit_transform(tqdm(corpus, desc='Calculating TF-iDF', total=len(reviews)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22641, 9694)\n"
     ]
    }
   ],
   "source": [
    "#12613 unique lemmas\n",
    "#9694 unique Porter stems\n",
    "#8190 unique Lancaster stems\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will go with Porter stemming because not much difference to Lancaster while retaining more meaning of words\n",
    "\n",
    "Only considers top 3000 stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b416f02acc734a3eb3d83d1f08634cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Calculating TF-iDF', max=22641, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), \n",
    "                             stop_words='english',\n",
    "                             analyzer=stemmed_words,\n",
    "                             max_features=3000,\n",
    "                             norm='l1')\n",
    "corpus = list(reviews['clean_text'])\n",
    "\n",
    "X = vectorizer.fit_transform(tqdm(corpus, desc='Calculating TF-iDF', total=len(reviews)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from kedro.io import PickleLocalDataSet\n",
    "\n",
    "data_set = PickleLocalDataSet(filepath=\"data.pkl\",\n",
    "                              backend='pickle',\n",
    "                              load_args=None,\n",
    "                              save_args=None)\n",
    "data_set.save(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
